{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b2cca4",
   "metadata": {},
   "source": [
    "# Track 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245bfe4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Paths\n",
    "# ---------------------------------------------------------\n",
    "BASE_PATH = Path(__file__).parents[1]\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "OUTPUTS_PATH = BASE_PATH / \"outputs\"\n",
    "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS_PATH = BASE_PATH / \"models\"\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE = DATA_PATH / \"trainset.json\"\n",
    "TEST_FILE = DATA_PATH / \"testset.json\"\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VALIDATION_REPORT_PATH = OUTPUTS_PATH / f\"validation_report_{timestamp}.txt\"\n",
    "\n",
    "NLTK_MODELS_PATH = BASE_PATH / \"models\" / \"corpora\"\n",
    "nltk.data.path.append(str(NLTK_MODELS_PATH))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Chain-of-Thought Prefixes\n",
    "# ---------------------------------------------------------\n",
    "cot_prefixes = [\n",
    "    \"Explain step by step and then give the final answer.\\nQuestion: \",\n",
    "    \"Reason carefully and provide the solution step by step.\\nQuestion: \",\n",
    "    \"Think thoroughly and give your answer with reasoning.\\nQuestion: \",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Text Cleaning / Lemmatization\n",
    "# ---------------------------------------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load JSON\n",
    "# ---------------------------------------------------------\n",
    "def load_json(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "train_data = load_json(TRAIN_FILE)\n",
    "test_data = load_json(TEST_FILE)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Prepare DataFrame using ALL tutors + CoT\n",
    "# ---------------------------------------------------------\n",
    "def prepare_dataframe_all_tutors(data, is_train=True):\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        convo_id = item[\"conversation_id\"]\n",
    "        convo_text = item[\"conversation_history\"]\n",
    "\n",
    "        for tutor, info in item[\"tutor_responses\"].items():\n",
    "            resp = info[\"response\"]\n",
    "            text_input = np.random.choice(cot_prefixes) + convo_text + \" \" + resp\n",
    "            text_input = clean_text(text_input)\n",
    "\n",
    "            row = {\n",
    "                \"conversation_id\": convo_id,\n",
    "                \"tutor\": tutor,\n",
    "                \"conversation_history\": convo_text,\n",
    "                \"response\": resp,\n",
    "                \"text\": text_input,\n",
    "            }\n",
    "\n",
    "            if is_train:\n",
    "                ann = info[\"annotation\"]\n",
    "                row[\"Mistake_Identification\"] = ann[\"Mistake_Identification\"]\n",
    "                row[\"Providing_Guidance\"] = ann[\"Providing_Guidance\"]\n",
    "\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Train and Test DataFrames\n",
    "df_train = prepare_dataframe_all_tutors(train_data, is_train=True)\n",
    "df_test = prepare_dataframe_all_tutors(test_data, is_train=False)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Features & Labels\n",
    "# ---------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_train[\"text\"],\n",
    "    df_train[\"Mistake_Identification\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_train[\"Mistake_Identification\"],\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000, ngram_range=(1, 2), sublinear_tf=True\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "X_test_vec = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Resampling + Ensemble Model\n",
    "# ---------------------------------------------------------\n",
    "# Base models\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=20, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "\n",
    "# Ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_reg), (\"rf\", rf)],\n",
    "    voting=\"soft\"  # use probabilities for better balance\n",
    ")\n",
    "\n",
    "# Resampling pipeline: SMOTE (oversample) + undersampling\n",
    "resample_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"smote\", SMOTE(sampling_strategy=\"not majority\", random_state=42)),\n",
    "        (\"under\", RandomUnderSampler(random_state=42)), # uncomment for under sampling\n",
    "        (\"clf\", ensemble),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "resample_pipeline.fit(X_train_vec, y_train)\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(resample_pipeline, MODELS_PATH / f\"ensemble_model_{timestamp}.joblib\")\n",
    "joblib.dump(vectorizer, MODELS_PATH / f\"tfidf_vectorizer_{timestamp}.joblib\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Cross-Validation (Macro F1)\n",
    "# ---------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    resample_pipeline, X_train_vec, y_train, cv=cv, scoring=\"f1_macro\"\n",
    ")\n",
    "print(\"Cross-validated Macro F1:\", cv_scores.mean())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation Evaluation\n",
    "# ---------------------------------------------------------\n",
    "y_val_pred = resample_pipeline.predict(X_val_vec)\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "report_str = f\"\"\"\n",
    "Validation Results:\n",
    "Accuracy: {acc}\n",
    "Macro F1: {f1}\n",
    "Cross-validated Macro F1: {cv_scores.mean()}\n",
    "\n",
    "Classification Report:\n",
    "{classification_report(y_val, y_val_pred)}\n",
    "\"\"\"\n",
    "\n",
    "print(report_str)\n",
    "\n",
    "# Save validation report\n",
    "with open(VALIDATION_REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_str)\n",
    "\n",
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    resample_pipeline, X_val_vec, y_val, cmap=\"Blues\", xticks_rotation=45\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "cm_file = OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_file)\n",
    "plt.close()\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "cm = confusion_matrix(y_val, y_val_pred, labels=resample_pipeline.classes_)\n",
    "pd.DataFrame(cm, index=resample_pipeline.classes_, columns=resample_pipeline.classes_).to_csv(\n",
    "    OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.csv\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Self-Consistency Prediction Function\n",
    "# ---------------------------------------------------------\n",
    "def self_consistency_predict(clf, vectorizer, texts, n_samples=3):\n",
    "    all_preds = []\n",
    "    for text in texts:\n",
    "        preds = [clf.predict(vectorizer.transform([text]))[0] for _ in range(n_samples)]\n",
    "        most_common = Counter(preds).most_common(1)[0][0]\n",
    "        all_preds.append(most_common)\n",
    "    return np.array(all_preds)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Test Predictions (with Self-Consistency)\n",
    "# ---------------------------------------------------------\n",
    "df_test[\"predicted_label\"] = self_consistency_predict(\n",
    "    resample_pipeline, vectorizer, df_test[\"text\"], n_samples=3\n",
    ")\n",
    "\n",
    "# If test set has labels, evaluate\n",
    "if \"Mistake_Identification\" in df_test.columns:\n",
    "    y_test = df_test[\"Mistake_Identification\"]\n",
    "    y_test_pred = df_test[\"predicted_label\"]\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print(f\"\\nTest Results:\\nAccuracy: {test_acc}\\nMacro F1: {test_f1}\")\n",
    "\n",
    "# Save CSV with predictions\n",
    "pred_path = OUTPUTS_PATH / f\"test_predictions_{timestamp}.csv\"\n",
    "df_test[\"actual_label\"] = df_test.get(\"Mistake_Identification\", \"\")\n",
    "df_test[[\"conversation_id\", \"tutor\", \"actual_label\", \"predicted_label\"]].to_csv(\n",
    "    pred_path, index=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTest predictions saved to {pred_path}\")\n",
    "print(f\"Plots and metrics saved in {OUTPUTS_PATH}\")\n",
    "print(f\"Trained ensemble model and vectorizer saved in {MODELS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ce7a1",
   "metadata": {},
   "source": [
    "# Track 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7bed2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "import datetime\n",
    "import unicodedata\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Paths\n",
    "# ---------------------------------------------------------\n",
    "BASE_PATH = Path(__file__).parents[1]\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "OUTPUTS_PATH = BASE_PATH / \"outputs\"\n",
    "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_PATH = BASE_PATH / \"results\"\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS_PATH = BASE_PATH / \"models\"\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE = DATA_PATH / \"trainset.json\"\n",
    "TEST_FILE = DATA_PATH / \"testset.json\"\n",
    "DEV_FILE = DATA_PATH / \"dev_testset.json\"\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VALIDATION_REPORT_PATH = OUTPUTS_PATH / f\"validation_report_{timestamp}.txt\"\n",
    "\n",
    "NLTK_MODELS_PATH = BASE_PATH / \"models\" / \"corpora\"\n",
    "nltk.data.path.append(str(NLTK_MODELS_PATH))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Chain-of-Thought Prefixes\n",
    "# ---------------------------------------------------------\n",
    "cot_prefixes = [\n",
    "    \"Explain step by step and then give the final answer.\\nQuestion: \",\n",
    "    \"Reason carefully and provide the solution step by step.\\nQuestion: \",\n",
    "    \"Think thoroughly and give your answer with reasoning.\\nQuestion: \",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Text Cleaning / Lemmatization\n",
    "# ---------------------------------------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Normalize unicode (e.g., convert full-width to ASCII, etc.)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    # Replace any unicode spaces (incl. \\u00a0, \\u200b, etc.) with a normal space\n",
    "    text = re.sub(r\"\\s+\", \" \", text, flags=re.UNICODE)\n",
    "    # Strip leading/trailing spaces\n",
    "    return text.strip()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load JSON\n",
    "# ---------------------------------------------------------\n",
    "def load_json(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "train_data = load_json(TRAIN_FILE)\n",
    "test_data = load_json(TEST_FILE)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Prepare DataFrame using ALL tutors + CoT\n",
    "# ---------------------------------------------------------\n",
    "def prepare_dataframe_all_tutors(data, is_train=True):\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        convo_id = item[\"conversation_id\"]\n",
    "        convo_text = item[\"conversation_history\"]\n",
    "\n",
    "        for tutor, info in item[\"tutor_responses\"].items():\n",
    "            resp = info[\"response\"]\n",
    "            text_input = np.random.choice(cot_prefixes) + convo_text + \" \" + resp\n",
    "            text_input = clean_text(text_input)\n",
    "\n",
    "            row = {\n",
    "                \"conversation_id\": convo_id,\n",
    "                \"tutor\": tutor,\n",
    "                \"conversation_history\": convo_text,\n",
    "                \"response\": resp,\n",
    "                \"text\": text_input,\n",
    "            }\n",
    "\n",
    "            if is_train:\n",
    "                ann = info[\"annotation\"]\n",
    "                row[\"Mistake_Identification\"] = ann[\"Mistake_Identification\"]\n",
    "                row[\"Providing_Guidance\"] = ann[\"Providing_Guidance\"]\n",
    "\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Train and Test DataFrames\n",
    "df_train = prepare_dataframe_all_tutors(train_data, is_train=True)\n",
    "df_test = prepare_dataframe_all_tutors(test_data, is_train=False)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Features & Labels\n",
    "# ---------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_train[\"text\"],\n",
    "    df_train[\"Providing_Guidance\"],  # <-- Changed to Track 2\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_train[\"Providing_Guidance\"],  # <-- Changed to Track 2\n",
    ")\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000, ngram_range=(1, 2), sublinear_tf=True\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "X_test_vec = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Resampling + Ensemble Model\n",
    "# ---------------------------------------------------------\n",
    "# Base models\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=20, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "\n",
    "# Ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_reg), (\"rf\", rf)],\n",
    "    voting=\"soft\"  # use probabilities for better balance\n",
    ")\n",
    "\n",
    "# Resampling pipeline: SMOTE (oversample) + undersampling\n",
    "resample_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"smote\", SMOTE(sampling_strategy=\"not majority\", random_state=42)),\n",
    "        (\"under\", RandomUnderSampler(random_state=42)), # uncomment for under sampling\n",
    "        (\"clf\", ensemble),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "resample_pipeline.fit(X_train_vec, y_train)\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(resample_pipeline, MODELS_PATH / f\"ensemble_model_{timestamp}.joblib\")\n",
    "joblib.dump(vectorizer, MODELS_PATH / f\"tfidf_vectorizer_{timestamp}.joblib\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Cross-Validation (Macro F1)\n",
    "# ---------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    resample_pipeline, X_train_vec, y_train, cv=cv, scoring=\"f1_macro\"\n",
    ")\n",
    "print(\"Cross-validated Macro F1:\", cv_scores.mean())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation Evaluation\n",
    "# ---------------------------------------------------------\n",
    "y_val_pred = resample_pipeline.predict(X_val_vec)\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "report_str = f\"\"\"\n",
    "Validation Results:\n",
    "Accuracy: {acc}\n",
    "Macro F1: {f1}\n",
    "Cross-validated Macro F1: {cv_scores.mean()}\n",
    "\n",
    "Classification Report:\n",
    "{classification_report(y_val, y_val_pred)}\n",
    "\"\"\"\n",
    "\n",
    "print(report_str)\n",
    "\n",
    "# Save validation report\n",
    "with open(VALIDATION_REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_str)\n",
    "\n",
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    resample_pipeline, X_val_vec, y_val, cmap=\"Blues\", xticks_rotation=45\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "cm_file = OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_file)\n",
    "plt.close()\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "cm = confusion_matrix(y_val, y_val_pred, labels=resample_pipeline.classes_)\n",
    "pd.DataFrame(cm, index=resample_pipeline.classes_, columns=resample_pipeline.classes_).to_csv(\n",
    "    OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Self-Consistency Prediction Function\n",
    "# ---------------------------------------------------------\n",
    "def self_consistency_predict(clf, vectorizer, texts, n_samples=3):\n",
    "    all_preds = []\n",
    "    for text in texts:\n",
    "        preds = [clf.predict(vectorizer.transform([text]))[0] for _ in range(n_samples)]\n",
    "        most_common = Counter(preds).most_common(1)[0][0]\n",
    "        all_preds.append(most_common)\n",
    "    return np.array(all_preds)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Test Predictions (with Self-Consistency)\n",
    "# ---------------------------------------------------------\n",
    "df_test[\"predicted_label\"] = self_consistency_predict(\n",
    "    resample_pipeline, vectorizer, df_test[\"text\"], n_samples=3\n",
    ")\n",
    "\n",
    "# If test set has labels, evaluate\n",
    "if \"Providing_Guidance\" in df_test.columns:  # <-- Changed to Track 2\n",
    "    y_test = df_test[\"Providing_Guidance\"]\n",
    "    y_test_pred = df_test[\"predicted_label\"]\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print(f\"\\nTest Results:\\nAccuracy: {test_acc}\\nMacro F1: {test_f1}\")\n",
    "\n",
    "# Save CSV with predictions\n",
    "pred_path = OUTPUTS_PATH / f\"test_predictions_{timestamp}.csv\"\n",
    "df_test[\"actual_label\"] = df_test.get(\"Providing_Guidance\", \"\")  # <-- Changed to Track 2\n",
    "df_test[[\"conversation_id\", \"tutor\", \"actual_label\", \"predicted_label\"]].to_csv(\n",
    "    pred_path, index=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Dev Set Predictions\n",
    "# ---------------------------------------------------------\n",
    "if DEV_FILE.exists():\n",
    "    dev_data = load_json(DEV_FILE)\n",
    "    df_dev = prepare_dataframe_all_tutors(dev_data, is_train=False)\n",
    "\n",
    "    # Predict with self-consistency\n",
    "    df_dev[\"predicted_label\"] = self_consistency_predict(\n",
    "        resample_pipeline, vectorizer, df_dev[\"text\"], n_samples=3\n",
    "    )\n",
    "\n",
    "    # Attach predictions back to JSON structure\n",
    "    updated_dev_data = []\n",
    "    for item in dev_data:\n",
    "        convo_id = item[\"conversation_id\"]\n",
    "        for tutor, info in item[\"tutor_responses\"].items():\n",
    "            match = df_dev[\n",
    "                (df_dev[\"conversation_id\"] == convo_id) &\n",
    "                (df_dev[\"tutor\"] == tutor)\n",
    "            ]\n",
    "            if not match.empty:\n",
    "                pred_label = match[\"predicted_label\"].values[0]\n",
    "                info[\"annotation\"] = {\"Providing_Guidance\": pred_label}  # <-- Changed to Track 2\n",
    "        updated_dev_data.append(item)\n",
    "\n",
    "    # Save as new JSON copy\n",
    "    DEV_RESULTS_FILE = RESULTS_PATH / f\"devset_with_predictions_{timestamp}.json\"\n",
    "    with open(DEV_RESULTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(updated_dev_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nDev predictions saved to {DEV_RESULTS_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e969bab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import joblib\n",
    "import datetime\n",
    "import unicodedata\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Paths\n",
    "# ---------------------------------------------------------\n",
    "BASE_PATH = Path(__file__).parents[1]\n",
    "DATA_PATH = BASE_PATH / \"data\"\n",
    "OUTPUTS_PATH = BASE_PATH / \"outputs\"\n",
    "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_PATH = BASE_PATH / \"results\"\n",
    "RESULTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODELS_PATH = BASE_PATH / \"models\"\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TRAIN_FILE = DATA_PATH / \"trainset.json\"\n",
    "TEST_FILE = DATA_PATH / \"testset.json\"\n",
    "DEV_FILE = DATA_PATH / \"dev_testset.json\"\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "VALIDATION_REPORT_PATH = OUTPUTS_PATH / f\"validation_report_{timestamp}.txt\"\n",
    "\n",
    "NLTK_MODELS_PATH = BASE_PATH / \"models\" / \"corpora\"\n",
    "nltk.data.path.append(str(NLTK_MODELS_PATH))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Chain-of-Thought Prefixes\n",
    "# ---------------------------------------------------------\n",
    "cot_prefixes = [\n",
    "    \"Explain step by step and then give the final answer.\\nQuestion: \",\n",
    "    \"Reason carefully and provide the solution step by step.\\nQuestion: \",\n",
    "    \"Think thoroughly and give your answer with reasoning.\\nQuestion: \",\n",
    "]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Text Cleaning / Lemmatization\n",
    "# ---------------------------------------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Normalize unicode (e.g., convert full-width to ASCII, etc.)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    # Replace any unicode spaces (incl. \\u00a0, \\u200b, etc.) with a normal space\n",
    "    text = re.sub(r\"\\s+\", \" \", text, flags=re.UNICODE)\n",
    "    # Strip leading/trailing spaces\n",
    "    return text.strip()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Load JSON\n",
    "# ---------------------------------------------------------\n",
    "def load_json(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "train_data = load_json(TRAIN_FILE)\n",
    "test_data = load_json(TEST_FILE)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Prepare DataFrame using ALL tutors + CoT\n",
    "# ---------------------------------------------------------\n",
    "def prepare_dataframe_all_tutors(data, is_train=True):\n",
    "    rows = []\n",
    "    for item in data:\n",
    "        convo_id = item[\"conversation_id\"]\n",
    "        convo_text = item[\"conversation_history\"]\n",
    "\n",
    "        for tutor, info in item[\"tutor_responses\"].items():\n",
    "            resp = info[\"response\"]\n",
    "            text_input = np.random.choice(cot_prefixes) + convo_text + \" \" + resp\n",
    "            text_input = clean_text(text_input)\n",
    "\n",
    "            row = {\n",
    "                \"conversation_id\": convo_id,\n",
    "                \"tutor\": tutor,\n",
    "                \"conversation_history\": convo_text,\n",
    "                \"response\": resp,\n",
    "                \"text\": text_input,\n",
    "            }\n",
    "\n",
    "            if is_train:\n",
    "                ann = info[\"annotation\"]\n",
    "                row[\"Mistake_Identification\"] = ann[\"Mistake_Identification\"]\n",
    "                row[\"Providing_Guidance\"] = ann[\"Providing_Guidance\"]\n",
    "\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Train and Test DataFrames\n",
    "df_train = prepare_dataframe_all_tutors(train_data, is_train=True)\n",
    "df_test = prepare_dataframe_all_tutors(test_data, is_train=False)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # Features & Labels\n",
    "# # ---------------------------------------------------------\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     df_train[\"text\"],\n",
    "#     df_train[\"Providing_Guidance\"],  # <-- Changed to Track 2\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=df_train[\"Providing_Guidance\"],  # <-- Changed to Track 2\n",
    "# )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Features & Labels\n",
    "# ---------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_train[\"text\"],\n",
    "    df_train[\"Mistake_Identification\"],  # <-- Reverted to Track 1\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_train[\"Mistake_Identification\"],  # <-- Reverted to Track 1\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=15000, ngram_range=(1, 2), sublinear_tf=True\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "X_test_vec = vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Resampling + Ensemble Model\n",
    "# ---------------------------------------------------------\n",
    "# Base models\n",
    "log_reg = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=20, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "\n",
    "# Ensemble\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"lr\", log_reg), (\"rf\", rf)],\n",
    "    voting=\"soft\"  # use probabilities for better balance\n",
    ")\n",
    "\n",
    "# Resampling pipeline: SMOTE (oversample) + undersampling\n",
    "resample_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"smote\", SMOTE(sampling_strategy=\"not majority\", random_state=42)),\n",
    "        (\"under\", RandomUnderSampler(random_state=42)), # uncomment for under sampling\n",
    "        (\"clf\", ensemble),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "resample_pipeline.fit(X_train_vec, y_train)\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(resample_pipeline, MODELS_PATH / f\"ensemble_model_{timestamp}.joblib\")\n",
    "joblib.dump(vectorizer, MODELS_PATH / f\"tfidf_vectorizer_{timestamp}.joblib\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Cross-Validation (Macro F1)\n",
    "# ---------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(\n",
    "    resample_pipeline, X_train_vec, y_train, cv=cv, scoring=\"f1_macro\"\n",
    ")\n",
    "print(\"Cross-validated Macro F1:\", cv_scores.mean())\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Validation Evaluation\n",
    "# ---------------------------------------------------------\n",
    "y_val_pred = resample_pipeline.predict(X_val_vec)\n",
    "\n",
    "acc = accuracy_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average=\"macro\")\n",
    "report_str = f\"\"\"\n",
    "Validation Results:\n",
    "Accuracy: {acc}\n",
    "Macro F1: {f1}\n",
    "Cross-validated Macro F1: {cv_scores.mean()}\n",
    "\n",
    "Classification Report:\n",
    "{classification_report(y_val, y_val_pred)}\n",
    "\"\"\"\n",
    "\n",
    "print(report_str)\n",
    "\n",
    "# Save validation report\n",
    "with open(VALIDATION_REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_str)\n",
    "\n",
    "# Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    resample_pipeline, X_val_vec, y_val, cmap=\"Blues\", xticks_rotation=45\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "cm_file = OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_file)\n",
    "plt.close()\n",
    "\n",
    "# Save confusion matrix as CSV\n",
    "cm = confusion_matrix(y_val, y_val_pred, labels=resample_pipeline.classes_)\n",
    "pd.DataFrame(cm, index=resample_pipeline.classes_, columns=resample_pipeline.classes_).to_csv(\n",
    "    OUTPUTS_PATH / f\"confusion_matrix_{timestamp}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Self-Consistency Prediction Function\n",
    "# ---------------------------------------------------------\n",
    "def self_consistency_predict(clf, vectorizer, texts, n_samples=3):\n",
    "    all_preds = []\n",
    "    for text in texts:\n",
    "        preds = [clf.predict(vectorizer.transform([text]))[0] for _ in range(n_samples)]\n",
    "        most_common = Counter(preds).most_common(1)[0][0]\n",
    "        all_preds.append(most_common)\n",
    "    return np.array(all_preds)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Test Predictions (with Self-Consistency)\n",
    "# ---------------------------------------------------------\n",
    "df_test[\"predicted_label\"] = self_consistency_predict(\n",
    "    resample_pipeline, vectorizer, df_test[\"text\"], n_samples=3\n",
    ")\n",
    "\n",
    "# # If test set has labels, evaluate\n",
    "# if \"Providing_Guidance\" in df_test.columns:  # <-- Changed to Track 2\n",
    "#     y_test = df_test[\"Providing_Guidance\"]\n",
    "#     y_test_pred = df_test[\"predicted_label\"]\n",
    "\n",
    "#     test_acc = accuracy_score(y_test, y_test_pred)\n",
    "#     test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "#     print(f\"\\nTest Results:\\nAccuracy: {test_acc}\\nMacro F1: {test_f1}\")\n",
    "\n",
    "# # Save CSV with predictions\n",
    "# pred_path = OUTPUTS_PATH / f\"test_predictions_{timestamp}.csv\"\n",
    "# df_test[\"actual_label\"] = df_test.get(\"Providing_Guidance\", \"\")  # <-- Changed to Track 2\n",
    "# df_test[[\"conversation_id\", \"tutor\", \"actual_label\", \"predicted_label\"]].to_csv(\n",
    "#     pred_path, index=False\n",
    "# )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# If test set has labels, evaluate\n",
    "# ---------------------------------------------------------\n",
    "if \"Mistake_Identification\" in df_test.columns:  # <-- Reverted to Track 1\n",
    "    y_test = df_test[\"Mistake_Identification\"]\n",
    "    y_test_pred = df_test[\"predicted_label\"]\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "    print(f\"\\nTest Results:\\nAccuracy: {test_acc}\\nMacro F1: {test_f1}\")\n",
    "\n",
    "# Save CSV with predictions\n",
    "pred_path = OUTPUTS_PATH / f\"test_predictions_{timestamp}.csv\"\n",
    "df_test[\"actual_label\"] = df_test.get(\"Mistake_Identification\", \"\")  # <-- Reverted to Track 1\n",
    "df_test[[\"conversation_id\", \"tutor\", \"actual_label\", \"predicted_label\"]].to_csv(\n",
    "    pred_path, index=False\n",
    ")\n",
    "\n",
    "\n",
    "# # ---------------------------------------------------------\n",
    "# # Dev Set Predictions\n",
    "# # ---------------------------------------------------------\n",
    "# if DEV_FILE.exists():\n",
    "#     dev_data = load_json(DEV_FILE)\n",
    "#     df_dev = prepare_dataframe_all_tutors(dev_data, is_train=False)\n",
    "\n",
    "#     # Predict with self-consistency\n",
    "#     df_dev[\"predicted_label\"] = self_consistency_predict(\n",
    "#         resample_pipeline, vectorizer, df_dev[\"text\"], n_samples=3\n",
    "#     )\n",
    "\n",
    "#     # Attach predictions back to JSON structure\n",
    "#     updated_dev_data = []\n",
    "#     for item in dev_data:\n",
    "#         convo_id = item[\"conversation_id\"]\n",
    "#         for tutor, info in item[\"tutor_responses\"].items():\n",
    "#             match = df_dev[\n",
    "#                 (df_dev[\"conversation_id\"] == convo_id) &\n",
    "#                 (df_dev[\"tutor\"] == tutor)\n",
    "#             ]\n",
    "#             if not match.empty:\n",
    "#                 pred_label = match[\"predicted_label\"].values[0]\n",
    "#                 info[\"annotation\"] = {\"Providing_Guidance\": pred_label}  # <-- Changed to Track 2\n",
    "#         updated_dev_data.append(item)\n",
    "\n",
    "#     # Save as new JSON copy\n",
    "#     DEV_RESULTS_FILE = RESULTS_PATH / f\"devset_with_predictions_{timestamp}.json\"\n",
    "#     with open(DEV_RESULTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(updated_dev_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "#     print(f\"\\nDev predictions saved to {DEV_RESULTS_FILE}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Dev Set Predictions\n",
    "# ---------------------------------------------------------\n",
    "if DEV_FILE.exists():\n",
    "    dev_data = load_json(DEV_FILE)\n",
    "    df_dev = prepare_dataframe_all_tutors(dev_data, is_train=False)\n",
    "\n",
    "    # Predict with self-consistency\n",
    "    df_dev[\"predicted_label\"] = self_consistency_predict(\n",
    "        resample_pipeline, vectorizer, df_dev[\"text\"], n_samples=3\n",
    "    )\n",
    "\n",
    "    # Attach predictions back to JSON structure\n",
    "    updated_dev_data = []\n",
    "    for item in dev_data:\n",
    "        convo_id = item[\"conversation_id\"]\n",
    "        for tutor, info in item[\"tutor_responses\"].items():\n",
    "            match = df_dev[\n",
    "                (df_dev[\"conversation_id\"] == convo_id) &\n",
    "                (df_dev[\"tutor\"] == tutor)\n",
    "            ]\n",
    "            if not match.empty:\n",
    "                pred_label = match[\"predicted_label\"].values[0]\n",
    "                info[\"annotation\"] = {\"Mistake_Identification\": pred_label}  # <-- Reverted to Track 1\n",
    "        updated_dev_data.append(item)\n",
    "\n",
    "    # Save as new JSON copy\n",
    "    DEV_RESULTS_FILE = RESULTS_PATH / f\"devset_with_predictions_{timestamp}.json\"\n",
    "    with open(DEV_RESULTS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(updated_dev_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nDev predictions saved to {DEV_RESULTS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
